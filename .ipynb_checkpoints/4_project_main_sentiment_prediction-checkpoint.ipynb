{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79c62ae6",
   "metadata": {},
   "source": [
    "# News Sentiment Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1abc242c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ca83732",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = joblib.load(\"log_reg_news.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "118f0e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "import re\n",
    "import string\n",
    "\n",
    "def preprocess(article):\n",
    "    article=article.strip().replace('\\n',' ')\n",
    "    article=\"\".join([i for i in article if i not in string.punctuation])\n",
    "    article=re.sub(r'\\s+', ' ', article)\n",
    "    return article.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51f49634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatization\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def lemmatizeNews(article):\n",
    "    tokens=re.split(' ',article)\n",
    "    stopwords=nltk.corpus.stopwords.words('english')\n",
    "    tokens= [i for i in tokens if i not in stopwords]\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    lemm_text = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    lemm_text=\" \".join(lemm_text)\n",
    "    return lemm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65aff4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf=joblib.load('vectorizer.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b96f3bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative News =  0\n",
      "Neutral News =  499\n",
      "Positive News =  1\n",
      "sentiment =  2\n",
      "Negative News =  0\n",
      "Neutral News =  500\n",
      "Positive News =  0\n",
      "sentiment =  1\n",
      "Negative News =  0\n",
      "Neutral News =  499\n",
      "Positive News =  1\n",
      "sentiment =  2\n",
      "Negative News =  1\n",
      "Neutral News =  498\n",
      "Positive News =  1\n",
      "sentiment =  0\n",
      "Negative News =  2\n",
      "Neutral News =  497\n",
      "Positive News =  1\n",
      "sentiment =  0\n"
     ]
    }
   ],
   "source": [
    "sentiments=[]\n",
    "for i in range(1,6):\n",
    "    path=os.path.join(f'NewsRecent\\\\Oct{i}.csv')\n",
    "    todayDf=pd.read_csv(path)\n",
    "    todayDf=todayDf.drop(\"web-scraper-order\",axis=1)\n",
    "    todayDf=todayDf.drop(\"web-scraper-start-url\",axis=1)\n",
    "\n",
    "    #preprocessing\n",
    "    todayDf['news1']=todayDf['News'].apply(lambda x: preprocess(x))\n",
    "\n",
    "\n",
    "    #lemmatization\n",
    "    todayDf['news']=todayDf['news1'].apply(lambda x: lemmatizeNews(x))\n",
    "    todayDf=todayDf.drop('News',axis=1)\n",
    "    todayDf=todayDf.drop('news1',axis=1)\n",
    "    \n",
    "    #vectorization\n",
    "    today=todayDf['news']\n",
    "    today=tf_idf.transform(today)\n",
    "    today=today.toarray()\n",
    "    \n",
    "    #todays prediction\n",
    "    today_pred=lr.predict(today)\n",
    "    negative=np.count_nonzero(today_pred == 0)\n",
    "    neutral=np.count_nonzero(today_pred == 1)\n",
    "    positive=np.count_nonzero(today_pred == 2)\n",
    "    print(\"Negative News = \",negative)\n",
    "    print(\"Neutral News = \",neutral)\n",
    "    print(\"Positive News = \",positive)\n",
    "    sentiment=-1\n",
    "    if positive==0 and negative==0:\n",
    "        sentiment=1\n",
    "    else:\n",
    "        if negative>=positive:\n",
    "            sentiment=0\n",
    "        else:\n",
    "            sentiment=2\n",
    "    print(\"sentiment = \",sentiment)\n",
    "    sentiments.append(sentiment)\n",
    "sentiments=pd.DataFrame(sentiments,columns =['output'])\n",
    "sentiments.to_csv(\"sentiments.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e8718a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
